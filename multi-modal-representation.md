# Multi-modal Representation

This repository is about Multi-modal Representation Learning and Application

## Table of Contents
- [Visual Representation Learning with Transformers](#visual-representation-learning-with-transformers)
- [Image-Text Matching (Visual-Semantic/Lingustic Embedding)](#image-text-matching--visual-semantic-lingustic-embedding-)

## Visual Representation Learning with Transformers

**HERO: Hierarchical Encoder for Video+Language Omni-representation Pre-training.**<br>
*Linjie Li, Yen-Chun Chen, Yu Cheng, Zhe Gan, Licheng Yu, Jingjing Liu.*<br>
EMNLP 2020. [[PDF](https://arxiv.org/abs/2005.00200)] [[Github](https://github.com/linjieli222/HERO_Video_Feature_Extractor)]

**Multimodal Pretraining Unmasked: Unifying the Vision and Language BERTs.**<br>
*Emanuele Bugliarello, Ryan Cotterell, Naoaki Okazaki, Desmond Elliott.*<br>
arxiv 2020. [[PDF](https://arxiv.org/abs/2011.15124)]

**MAG: Integrating Multimodal Information in Large Pretrained Transformers.**<br>
*Wasifur Rahman, Md. Kamrul Hasan, Sangwu Lee, Amir Zadeh, Chengfeng Mao, Louis-Philippe Morency, Ehsan Hoque.*<br>
ACL 2020. [[PDF](https://arxiv.org/abs/1908.05787)] [[Github](https://github.com/WasifurRahman/BERT_multimodal_transformer)]

**UNITER: UNiversal Image-TExt Representation Learning.**<br> 
*Yen-Chun Chen, Linjie Li, Licheng Yu, Ahmed El Kholy, Faisal Ahmed, Zhe Gan, Yu Cheng, Jingjing Liu.*<br>
ECCV 2020. [[PDF](https://arxiv.org/abs/1909.11740)] [[Github](https://github.com/ChenRocks/UNITER)]

**VL-BERT: Pre-training of Generic Visual-Linguistic Representations.**<br>
*Weijie Su, Xizhou Zhu, Yue Cao, Bin Li, Lewei Lu, Furu Wei, Jifeng Dai.*<br>
ICLR 2020. [[PDF] (https://arxiv.org/abs/190 8.08530)] [[Github](https://github.com/jackroos/VL-BERT)]

**VILLA: Large-Scale Adversarial Training for Vision-and-Language Representation Learning.**<br>
*Zhe Gan, Yen-Chun Chen, Linjie Li, Chen Zhu, Yu Cheng, Jingjing Liu.*<br>
NeurIPS 2020. [[PDF](https://arxiv.org/abs/2006.06195)] [[Github](https://github.com/zhegan27/LXMERT-AdvTrain)]

**LXMERT: Learning Cross-Modality Encoder Representations from Transformers.**<br>
*Hao Tan, Mohit Bansal.*<br>
EMNLP 2019. [[PDF](https://arxiv.org/abs/1908.07490)] [[Github](https://github.com/airsplay/lxmert)]

**ViLBERT: Pretraining Task-Agnostic Visiolinguistic Representations for Vision-and-Language Tasks.**<br>
*Jiasen Lu, Dhruv Batra, Devi Parikh, Stefan Lee.*<br>
arxiv 2020. [[PDF](https://arxiv.org/abs/1908.02265)] [[Github](https://github.com/jiasenlu/vilbert_beta)]

**12-in-1: Multi-Task Vision and Language Representation Learning.**<br>
*Jiasen Lu, Vedanuj Goswami, Marcus Rohrbach, Devi Parikh, Stefan Lee.*<br>
CVPR 2020. [[PDF](https://arxiv.org/abs/1912.02315)] [[Github](https://github.com/facebookresearch/vilbert-multi-task)]

**VisualBERT: A Simple and Performant Baseline for Vision and Language.**<br>
*Liunian Harold Li, Mark Yatskar, Da Yin, Cho-Jui Hsieh, Kai-Wei Chang.*<br>
NeurIPS 2020. [[PDF](https://arxiv.org/abs/1908.03557)] [[Github](https://github.com/uclanlp/visualbert)]

## Image-Text Matching (Visual-Semantic/Lingustic Embedding)

[a collection of Image-Text Matching (Visual-Semantic/Lingustic Embedding)](https://blog.csdn.net/weixin_42/article/details/104275300)

**Natural Language Rationales with Full-Stack Visual Reasoning: From Pixels to Semantic Frames to Commonsense Graphs.**<br>
*Ana MarasoviÄ‡, Chandra Bhagavatula, Jae Sung Park, Ronan Le Bras, Noah A. Smith, Yejin Choi.*<br>
EMNLP 2020. [[PDF](https://arxiv.org/abs/2010.07526)]

**Vokenization: Improving Language Understanding with Contextualized, Visual-Grounded Supervision.**<br>
*Hao Tan, Mohit Bansal.*<br>
EMNLP 2020. [[PDF](https://arxiv.org/abs/2010.06775)] [[Github](https://github.com/airsplay/vokenization)]

**VIVO: Surpassing Human Performance in Novel Object Captioning with Visual Vocabulary Pre-Training.**<br>
*Xiaowei Hu Xi Yin Kevin Lin Lijuan Wang Lei Zhang Jianfeng Gao Zicheng Liu.*<br>
arxiv 2020. [[PDF](https://www.microsoft.com/en-us/research/publication/vivo-surpassing-human-performance-in-novel-object-captioning-with-visual-vocabulary-pre-training/)] [[Project](https://www.microsoft.com/en-us/research/project/azure-florence-vision-and-language/)]

**CVSE: Consensus-Aware Visual-Semantic Embedding for Image-Text Matching.**<br>
*Haoran Wang, Ying Zhang, Zhong Ji, Yanwei Pang, Lin Ma.*<br>
ECCV 2020. [[PDF] (https://arxiv.org/abs/2007.08883)] [[Github](https://github.com/BruceW91/CVSE)]

**Visual Semantic Reasoning for Image-Text Matching.**<br>
*Kunpeng Li, Yulun Zhang, Kai Li, Yuanyuan Li, Yun Fu.*<br>
ICCV 2019. [[PDF] (arxiv.org/abs/1909.02701)] [[Github](https://github.com/KunpengLi1994/VSRN)]

**Cross-modal Scene Graph Matching for Relationship-aware Image-Text Retrieval.**<br>
*Sijin Wang, Ruiping Wang, Ziwei Yao, Shiguang Shan, xilin Chen.*<br>
WACV 2020. [[PDF](https://arxiv.org/abs/1910.0513)]

**SAN: Saliency-Guided- Attention Network for Image-Sentence Matching.**<br>
*Zhong Ji, Haoran Wang, Jungong Han, Yanwei Pang.*<br>
ICCV 2019. [[PDF](https://arxiv.org/abs/1904.09471v1)]

**VSE++: Improving Visual-Semantic- Embeddings with Hard Negatives.**<br>
*Fartash Faghri, David. Fleet, Jamie Ryan Kiros, Sanja Fidler.*<br>
BMVC 2018. [[PDF](https://arxiv.org/abs/1707.05612)] [[Github](https://github.com/fartashf/vsepp)]

**Deep Fragment Embeddings for Bidirectional Image Sentence Mapping.**<br>
*Andrej Karpathy, Armand Joulin, Li Fei-Fei.*<br>
NeurIPS 2014. [[PDF](https://arxiv.org/abs/1406.5679)]

**DeViSE: Deep Visual/Semantic Embedding Model.**<br>
*Andrea Frome, Greg Corrado, Jonathon ShLens, Samy Bengio, Jeffrey Dean, Marc'Aurelio Ranzato Tomas Mikolov.*<br> 
NeurIPS 2013. [[PDF](https://static.googleusercontent.com/media/researchgoogle.com/zh-CN/pubs/archive/41473.pdf)]

**Learning Representations from Audio-Visual Spatial Alignment.**<br>
*Pedro Morgado, Yi Li, Nuno Vasconcelos.*<br>
NeurIPS 2020. [[PDF](https://arxiv.org/abs/2011.01819)]

**Representation Learning via Invariant Causal Mechanisms.**<br>
*Jovana Mitrovic, Brian McWilliams, Jacob Walker, Lars Buesing, Charles Blundell.*<br>
arxiv 2020. [[PDF](https://arxiv.org/abs/2010.07922)] 

**Contrastive Learning of General-Purpose Audio Representations.**<br>
*Aaqib Saeed, David Grangier, Neil Zeghidour.*<br>
arxiv 2020. [[PDF](https://arxiv.org/abs/2010.10915)]

**Learning Visual Representations for Transfer Learning by Suppressing Texture.**<br>
*Shlok Mishra, Anshul Shah, Ankan Bansal, Jonghyun Choi, Abhinav Shrivastava, Abhishek Sharma, David Jacobs.*<br>
arxiv 2020. [[PDF](https://arxiv.org/abs/2011.01901)]

## Unsupervised Visual Representation Learning

**Propagate Yourself: Exploring Pixel-Level Consistency for Unsupervised Visual Representation Learning.**<br>
*Zhenda Xie, Yutong Lin, Zheng Zhang, Yue Cao, Stephen Lin, Han Hu.*<br>
arxiv 2020. [[PDF](https://arxiv.org/abs/2011.10043)] [[Github](https://github.com/lucidrains/pixel-level-contrastive-learning)]